{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f3e615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd31d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,math\n",
    "from torch import tensor,nn,optim\n",
    "from torch.nn import init\n",
    "from functools import partial\n",
    "import torchvision.transforms.functional as TF,torch.nn.functional as F\n",
    "from scipy import linalg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4141b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# autoencoder\n",
    "def conv(ni, nf, ks=3, stride=2, act=True):\n",
    "    res = nn.Conv2d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2)\n",
    "    if act: res = nn.Sequential(res, nn.ReLU())\n",
    "    return res\n",
    "\n",
    "def deconv(ni, nf, ks=3, act=True):\n",
    "    layers = [nn.ConvTranspose2d(ni, nf, kernel_size=ks, stride=2, padding=ks//2)]\n",
    "    if act: layers.append(nn.ReLU())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "ae = nn.Sequential(   #28x28\n",
    "    nn.ZeroPad2d(2),  #32x32\n",
    "    conv(1,2),        #16x16\n",
    "    conv(2,4),        #8x8\n",
    "#     conv(4,8),        #4x4\n",
    "#     deconv(8,4),      #8x8\n",
    "    deconv(4,2),      #16x16\n",
    "    deconv(2,1, act=False), #32x32\n",
    "    nn.ZeroPad2d(-2), #28x28\n",
    "    nn.Sigmoid()\n",
    ").to(def_device)\n",
    "\n",
    "ni,nh,nl = 784,400,200\n",
    "def lin(ni, nf, act=nn.SiLU, norm=nn.BatchNorm1d, bias=True):\n",
    "    layers = nn.Sequential(nn.Linear(ni, nf, bias=bias))\n",
    "    if act : layers.append(act())\n",
    "    if norm: layers.append(norm(nf))\n",
    "    return layers\n",
    "\n",
    "def init_weights(m, leaky=0.):\n",
    "    if isinstance(m, (nn.Conv1d,nn.Conv2d,nn.Conv3d,nn.Linear)): init.kaiming_normal_(m.weight, a=leaky)\n",
    "\n",
    "iw = partial(init_weights, leaky=0.2)\n",
    "\n",
    "class Autoenc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(lin(ni, nh), lin(nh, nh), lin(nh, nl))\n",
    "        self.dec = nn.Sequential(lin(nl, nh), lin(nh, nh), lin(nh, ni, act=None))\n",
    "        iw(self)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        return self.dec(x)\n",
    "\n",
    "# VAE (Variational ae), z is latent variable\n",
    "class VAE(nn.Module): \n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim): \n",
    "        super(VAE, self).__init__() \n",
    "        # ç¼–ç å™¨éƒ¨åˆ† \n",
    "        self.fc1  = nn.Linear(input_dim, hidden_dim) \n",
    "        self.fc_mu  = nn.Linear(hidden_dim, latent_dim) \n",
    "        self.fc_logvar  = nn.Linear(hidden_dim, latent_dim) \n",
    "        # è§£ç å™¨éƒ¨åˆ† \n",
    "        self.fc2  = nn.Linear(latent_dim, hidden_dim) \n",
    "        self.fc3  = nn.Linear(hidden_dim, input_dim) \n",
    "\n",
    "    def encode(self, x): \n",
    "        h = torch.relu(self.fc1(x))  \n",
    "        mu = self.fc_mu(h)  \n",
    "        logvar = self.fc_logvar(h)  \n",
    "        return mu, logvar \n",
    " \n",
    "    def reparameterize(self, mu, logvar): \n",
    "        std = torch.exp(0.5  * logvar) \n",
    "        eps = torch.randn_like(std)  \n",
    "        return mu + eps * std \n",
    " \n",
    "    def decode(self, z): \n",
    "        h = torch.relu(self.fc2(z))  \n",
    "        return torch.sigmoid(self.fc3(h))  \n",
    " \n",
    "    def forward(self, x): \n",
    "        mu, logvar = self.encode(x)  \n",
    "        z = self.reparameterize(mu,  logvar) \n",
    "        return self.decode(z),  mu, logvar \n",
    "\n",
    "class VAE2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(lin(ni, nh), lin(nh, nh))\n",
    "        self.mu,self.lv = lin(nh, nl, act=None),lin(nh, nl, act=None)\n",
    "        self.dec = nn.Sequential(lin(nl, nh), lin(nh, nh), lin(nh, ni, act=None))\n",
    "        iw(self)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        mu,lv = self.mu(x),self.lv(x)\n",
    "        z = mu + (0.5*lv).exp()*torch.randn_like(lv)\n",
    "        return self.dec(z),mu,lv\n",
    "\n",
    "# Kullback-Leibler Divergence Loss\n",
    "def kld_loss(inp, x):\n",
    "    x_hat,mu,lv = inp\n",
    "    return -0.5 * (1 + lv - mu.pow(2) - lv.exp()).mean()\n",
    "# Binary Cross-Entropy Loss\n",
    "def bce_loss(inp, x): return F.binary_cross_entropy_with_logits(inp[0], x)\n",
    "\n",
    "def vae_loss(inp, x): return kld_loss(inp, x) + bce_loss(inp,x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb4cb2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralRelu(nn.Module):\n",
    "    def __init__(self, leak=None, sub=None, maxv=None):\n",
    "        super().__init__()\n",
    "        self.leak,self.sub,self.maxv = leak,sub,maxv\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = F.leaky_relu(x,self.leak) if self.leak is not None else F.relu(x)\n",
    "        if self.sub is not None: x -= self.sub\n",
    "        if self.maxv is not None: x.clamp_max_(self.maxv)\n",
    "        return x\n",
    "def noop (x=None, *args, **kwargs):\n",
    "    \"Do nothing\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESNET\n",
    "act_gr = partial(GeneralRelu, leak=0.1, sub=0.4)\n",
    "\n",
    "def _conv_block(ni, nf, stride, act=act_gr, norm=None, ks=3):\n",
    "    return nn.Sequential(conv(ni, nf, stride=1, act=act, norm=norm, ks=ks),\n",
    "                         conv(nf, nf, stride=stride, act=None, norm=norm, ks=ks))\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=1, ks=3, act=act_gr, norm=None):\n",
    "        super().__init__()\n",
    "        self.convs = _conv_block(ni, nf, stride, act=act, ks=ks, norm=norm)\n",
    "        self.idconv = noop if ni==nf else conv(ni, nf, ks=1, stride=1, act=None)\n",
    "        self.pool = noop if stride==1 else nn.AvgPool2d(2, ceil_mode=True)\n",
    "        self.act = act()\n",
    "\n",
    "    def forward(self, x): return self.act(self.convs(x) + self.idconv(self.pool(x)))\n",
    "\n",
    "def get_model(act=nn.ReLU, nfs=(8,16,32,64,128,256), norm=nn.BatchNorm2d):\n",
    "    layers = [ResBlock(1, 8, stride=1, act=act, norm=norm)]\n",
    "    layers += [ResBlock(nfs[i], nfs[i+1], act=act, norm=norm, stride=2) for i in range(len(nfs)-1)]\n",
    "    layers += [nn.Flatten(), nn.Linear(nfs[-1], 10, bias=False), nn.BatchNorm1d(10)]\n",
    "    return nn.Sequential(*layers).to(def_device)\n",
    "\n",
    "# ResNetç±»çš„åŸºæœ¬ç»“æ„\n",
    "# ResNetç±»é€šå¸¸ç»§æ‰¿è‡ªPyTorchçš„nn.ModuleåŸºç±»ï¼ŒåŒ…å«__init__åˆå§‹åŒ–æ–¹æ³•å’Œforwardå‰å‘ä¼ æ’­æ–¹æ³•ã€‚åœ¨__init__ä¸­å®šä¹‰ç½‘ç»œå„å±‚ç»“æ„ï¼Œforwardæ–¹æ³•åˆ™æè¿°æ•°æ®åœ¨ç½‘ç»œä¸­çš„æµåŠ¨é¡ºåºã€‚\n",
    "# ResNetä¸»è¦ç”±åˆå§‹å·ç§¯å±‚ã€æ‰¹é‡å½’ä¸€åŒ–å±‚ã€ReLUæ¿€æ´»å‡½æ•°ã€æœ€å¤§æ± åŒ–å±‚ã€4ä¸ªæ®‹å·®å—å±‚ï¼ˆlayer1-layer4ï¼‰ã€å¹³å‡æ± åŒ–å±‚å’Œå…¨è¿æ¥å±‚ç»„æˆã€‚\n",
    "# æ®‹å·®å—å®ç°\n",
    "# ResNetåŒ…å«ä¸¤ç§æ®‹å·®å—ï¼šBasicBlockå’ŒBottleneckã€‚BasicBlockç”¨äºè¾ƒæµ…çš„ç½‘ç»œï¼ˆå¦‚ResNet18/34ï¼‰ï¼Œç”±ä¸¤ä¸ª3x3å·ç§¯å±‚ç»„æˆï¼›Bottleneckç”¨äºæ·±å±‚ç½‘ç»œï¼ˆå¦‚ResNet50/101/152ï¼‰ï¼Œç”±1x1ã€3x3ã€1x1ä¸‰ä¸ªå·ç§¯å±‚æ„æˆï¼Œ\n",
    "# ç¬¬ä¸€ä¸ª1x1å·ç§¯ç”¨äºé™ç»´ï¼Œæœ€åä¸€ä¸ª1x1å·ç§¯æ¢å¤ç»´åº¦ã€‚æ¯ä¸ªå·ç§¯å±‚åéƒ½è·Ÿéšæ‰¹é‡å½’ä¸€åŒ–å’ŒReLUæ¿€æ´»ã€‚æ®‹å·®è¿æ¥é€šè¿‡å°†è¾“å…¥ç›´æ¥åŠ åˆ°è¾“å‡ºä¸Šæ¥å®ç°ï¼Œå½“ç»´åº¦ä¸åŒ¹é…æ—¶ä½¿ç”¨1x1å·ç§¯è¿›è¡Œä¸‹é‡‡æ ·ã€‚\n",
    "# forwardæ–¹æ³•å®ç°\n",
    "# forwardæ–¹æ³•å®šä¹‰äº†æ•°æ®æµåŠ¨è·¯å¾„ï¼šå…ˆé€šè¿‡åˆå§‹å·ç§¯å±‚ï¼ˆconv1ï¼‰ã€æ‰¹é‡å½’ä¸€åŒ–ï¼ˆbn1ï¼‰ã€ReLUå’Œæœ€å¤§æ± åŒ–ï¼ˆmaxpoolï¼‰ï¼Œç„¶åä¾æ¬¡é€šè¿‡4ä¸ªæ®‹å·®å—å±‚ï¼ˆlayer1-layer4ï¼‰ï¼Œæœ€åç»è¿‡å¹³å‡æ± åŒ–ï¼ˆavgpoolï¼‰ã€å±•å¹³ï¼ˆflattenï¼‰å’Œå…¨è¿æ¥å±‚ï¼ˆfcï¼‰ã€‚\n",
    "# åœ¨PyTorchä¸­ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡å®ä¾‹è°ƒç”¨ï¼ˆå¦‚model(input)ï¼‰æ¥è‡ªåŠ¨è§¦å‘forwardæ–¹æ³•ï¼Œè¿™å¾—ç›ŠäºPythonçš„__call__æœºåˆ¶ã€‚\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1 \n",
    "    \n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1  = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1  = nn.BatchNorm2d(planes)\n",
    "        self.conv2  = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2  = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.shortcut  = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes: \n",
    "            self.shortcut  = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,  kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes) \n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x))) \n",
    "        out = self.bn2(self.conv2(out)) \n",
    "        out += self.shortcut(x) \n",
    "        out = F.relu(out) \n",
    "        return out \n",
    " \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes  = 64 \n",
    "        \n",
    "        self.conv1  = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1  = nn.BatchNorm2d(64)\n",
    "        self.maxpool  = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1  = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2  = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3  = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4  = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        \n",
    "        self.avgpool  = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc  = nn.Linear(512*block.expansion,  num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes,  planes, stride))\n",
    "            self.in_planes  = planes * block.expansion  \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x))) \n",
    "        x = self.maxpool(x) \n",
    "        \n",
    "        x = self.layer1(x) \n",
    "        x = self.layer2(x) \n",
    "        x = self.layer3(x) \n",
    "        x = self.layer4(x) \n",
    "        \n",
    "        x = self.avgpool(x) \n",
    "        x = torch.flatten(x,  1)\n",
    "        x = self.fc(x) \n",
    "        return x \n",
    " \n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ed9e6",
   "metadata": {},
   "source": [
    "# Denoising Diffusion Probabilistic Models(DDPM)\n",
    "The model described in the seminal 2020 paper [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) (DDPM). For more context, while diffusion models were technically invented [back in 2015](https://arxiv.org/abs/1503.03585)\n",
    "\n",
    "DDPM is trained quite simply in a few steps:\n",
    "1. randomly select some timesteps in an iterative noising process.\n",
    "2. Add noise corresponding to this timestep to the original image. For increasing timesteps, the variance of the noise increases.\n",
    "3. Pass in this noisy image and the timestep to our model\n",
    "4. Model is trained with an MSE loss between the model output and the amount of noise added to the image\n",
    "\n",
    "# DDPM æ ¸å¿ƒåŸç†ç®—æ³•è¯¦è§£ \n",
    " \n",
    "**Denoising Diffusion Probabilistic Models (DDPM)** æ˜¯ä¸€ç§åŸºäºé©¬å°”å¯å¤«é“¾çš„ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡é€æ­¥åŠ å™ªå’Œå»å™ªè¿‡ç¨‹å®ç°æ•°æ®ç”Ÿæˆã€‚ä»¥ä¸‹æ˜¯å…¶æ ¸å¿ƒåŸç†ç®—æ³•ï¼š\n",
    " \n",
    "## ä¸€ã€å‰å‘æ‰©æ•£è¿‡ç¨‹ï¼ˆåŠ å™ªï¼‰\n",
    "å°†åŸå§‹æ•°æ® $x_0$ é€æ­¥æ·»åŠ é«˜æ–¯å™ªå£°ï¼Œç»è¿‡ $T$ æ­¥è½¬åŒ–ä¸ºçº¯å™ªå£° $x_T$ï¼š\n",
    " \n",
    "$$\n",
    "q(x_t|x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1-\\beta_t}x_{t-1}, \\beta_t I)\n",
    "è¡¨ç¤ºåœ¨ç»™å®šå‰ä¸€æ­¥çŠ¶æ€x_{t-1}çš„æ¡ä»¶ä¸‹ï¼Œå½“å‰çŠ¶æ€x_{t}çš„åˆ†å¸ƒæ˜¯ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒï¼ˆæ­£æ€åˆ†å¸ƒï¼‰ã€‚å…·ä½“å‚æ•°å¦‚ä¸‹ï¼š\\\\\n",
    "å‡å€¼ï¼ˆmeanï¼‰ï¼š \\sqrt{1-\\beta_t}x_{t-1}  \n",
    "æ–¹å·®ï¼ˆvarianceï¼‰ï¼š\\beta_t Iï¼ŒIæ˜¯å•ä½çŸ©é˜µï¼Œè¡¨ç¤ºå„ä¸ªç»´åº¦ç‹¬ç«‹ä¸”æ–¹å·®ç›¸åŒ\n",
    "$$\n",
    "### 1. å‡å€¼åˆ†é‡ï¼š$\\sqrt{1-\\beta_t}x_{t-1}$\n",
    "| **ç‰¹æ€§**        | **æ•°å­¦æ„ä¹‰**               | **ç‰©ç†æ„ä¹‰**                     |\n",
    "|-----------------|--------------------------|----------------------------------|\n",
    "| ç¼©å‡å› å­        | $\\sqrt{1-\\beta_t} < 1$   | å¯¹å‰æ­¥æ•°æ®çš„ç¼©æ”¾è¡°å‡             |\n",
    "| ä¿¡å·ä¿ç•™        | ä¸$\\beta_t$æˆåæ¯”         | $\\beta_t$è¶Šå¤§ï¼Œä¿¡å·ä¿ç•™è¶Šå°‘      |\n",
    "| ç¨³å®šæ€§ä¿éšœ      | é˜²æ­¢æ•°æ®å¹…åº¦æ— é™å¢é•¿       | ç»´æŒæ‰©æ•£è¿‡ç¨‹çš„æ•°å€¼ç¨³å®š           |\n",
    " \n",
    "### 2. æ–¹å·®åˆ†é‡ï¼š$\\beta_t I$\n",
    "| **ç‰¹æ€§**        | **æ•°å­¦æ„ä¹‰**               | **ç‰©ç†æ„ä¹‰**                     |\n",
    "|-----------------|--------------------------|----------------------------------|\n",
    "| å„å‘åŒæ€§        | $I$ ä¸ºå•ä½çŸ©é˜µ           | å„ç»´åº¦ç‹¬ç«‹åŒåˆ†å¸ƒå™ªå£°             |\n",
    "| å™ªå£°å¼ºåº¦        | $\\beta_t$ æ§åˆ¶æ–¹å·®å¤§å°    | å†³å®šå½“å‰æ­¥æ·»åŠ çš„å™ªå£°é‡           |\n",
    "| æ—¶é—´ä¾èµ–æ€§      | $\\beta_t$ éš $t$ å•è°ƒé€’å¢ | éšæ—¶é—´æ­¥å¢åŠ å™ªå£°é€æ­¥å¢å¼º         |\n",
    " \n",
    "## âš™ï¸ å‚æ•°è§£é‡Š\n",
    "### $\\beta_t$ - å™ªå£°è°ƒåº¦å‚æ•° \n",
    "- **å–å€¼èŒƒå›´**ï¼š$(0,1)$  \n",
    "- **è°ƒåº¦ç‰¹æ€§**ï¼š  \n",
    "  $$\\beta_1 < \\beta_2 < \\cdots < \\beta_T$$  \n",
    "  ï¼ˆå…¸å‹å€¼ï¼š$\\beta_1â‰ˆ0.0001$, $\\beta_Tâ‰ˆ0.02$ï¼‰\n",
    "- **ä½œç”¨æœºåˆ¶**ï¼š  \n",
    "  æ§åˆ¶å™ªå£°æ³¨å…¥é€Ÿç‡ï¼Œå†³å®šæ‰©æ•£è½¨è¿¹å½¢çŠ¶ \n",
    " \n",
    "### $1-\\beta_t$ - ä¿¡å·ä¿ç•™å› å­\n",
    "- **ç‰©ç†ä½œç”¨**ï¼š  \n",
    "  å¹³è¡¡ä¿¡å·è¡°å‡ä¸å™ªå£°æ³¨å…¥çš„æ¯”ä¾‹å…³ç³»  \n",
    "  $$\\text{ä¿¡å·ä¿ç•™é‡} \\propto \\sqrt{1-\\beta_t}$$  \n",
    "  $$\\text{å™ªå£°æ³¨å…¥é‡} \\propto \\sqrt{\\beta_t}$$\n",
    "\n",
    "\n",
    "**å…³é”®ç‰¹æ€§ï¼š**\n",
    "1. **é—­å¼è¡¨è¾¾**ï¼šä»»æ„æ—¶åˆ» $t$ çš„çŠ¶æ€å¯ç›´æ¥ä» $x_0$ è®¡ç®—ï¼š\n",
    "   $$\n",
    "   x_t = \\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0,I)\n",
    "   $$\n",
    "   å…¶ä¸­ $\\alpha_t = 1-\\beta_t$, $\\bar{\\alpha}_t = \\prod_{i=1}^t \\alpha_i$\n",
    " \n",
    "2. **å™ªå£°è°ƒåº¦**ï¼š$\\beta_t$ æ»¡è¶³ $0 < \\beta_1 < \\beta_2 < \\cdots < \\beta_T < 1$ï¼Œé€šå¸¸é‡‡ç”¨çº¿æ€§æˆ–ä½™å¼¦è°ƒåº¦ \n",
    " \n",
    "## äºŒã€åå‘å»å™ªè¿‡ç¨‹ï¼ˆç”Ÿæˆï¼‰\n",
    "å­¦ä¹ ä»å™ªå£° $x_T$ é€æ­¥é‡å»ºæ•°æ® $x_0$ çš„é€†è¿‡ç¨‹ï¼š\n",
    " \n",
    "$$\n",
    "p_\\theta(x_{t-1}|x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t,t), \\Sigma_\\theta(x_t,t))\n",
    "$$\n",
    " \n",
    "**å‚æ•°åŒ–å½¢å¼ï¼š**\n",
    "$$\n",
    "\\mu_\\theta(x_t,t) = \\frac{1}{\\sqrt{\\alpha_t}}\\left( x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\epsilon_\\theta(x_t,t) \\right)\n",
    "$$\n",
    "$$\n",
    "\\Sigma_\\theta(x_t,t) = \\sigma_t^2 I, \\quad \\sigma_t^2 = \\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_t}\\beta_t\n",
    "$$\n",
    " \n",
    "## ä¸‰ã€è®­ç»ƒç›®æ ‡ï¼ˆç®€åŒ–æŸå¤±å‡½æ•°ï¼‰\n",
    "ä¼˜åŒ–å™ªå£°é¢„æµ‹ç½‘ç»œ $\\epsilon_\\theta$ï¼š\n",
    " \n",
    "$$\n",
    "\\mathcal{L}_{simple} = \\mathbb{E}_{t,x_0,\\epsilon} \\left[ \\| \\epsilon - \\epsilon_\\theta(\\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\epsilon, t) \\|^2 \\right]\n",
    "$$\n",
    " \n",
    "**è®­ç»ƒæµç¨‹ï¼š**\n",
    "1. é‡‡æ ·æ•°æ® $x_0 \\sim q(x_0)$ \n",
    "2. éšæœºé€‰æ‹©æ—¶é—´æ­¥ $t \\sim \\text{Uniform}(1,T)$ \n",
    "3. é‡‡æ ·å™ªå£° $\\epsilon \\sim \\mathcal{N}(0,I)$\n",
    "4. è®¡ç®—æ¢¯åº¦ä¸‹é™æ›´æ–° $\\nabla_\\theta \\|\\epsilon - \\epsilon_\\theta(x_t,t)\\|^2$\n",
    "\n",
    "## ğŸ“Œ æ ¸å¿ƒé‡‡æ ·å…¬å¼\n",
    "$$\n",
    "x_{t-1} = \\underbrace{\\mu_\\theta(x_t, t)}_{\\text{ç¡®å®šæ€§æˆåˆ†}} + \\underbrace{\\sigma_t \\cdot z}_{\\text{éšæœºæˆåˆ†}},\\quad z \\sim \\mathcal{N}(0,I)\n",
    "$$\n",
    " \n",
    "## ğŸ” åŒç»„åˆ†ç‰©ç†æ„ä¹‰è§£æ\n",
    "### ğŸ¯ ç¡®å®šæ€§æˆåˆ† $\\mu_\\theta(x_t, t)$\n",
    "| **ç‰¹æ€§**       | **æ•°å­¦æœ¬è´¨**                  | **ç”Ÿæˆä½œç”¨**                     |\n",
    "|----------------|-----------------------------|--------------------------------|\n",
    "| å»å™ªæ–¹å‘é¢„æµ‹   | ç¥ç»ç½‘ç»œ $\\epsilon_\\theta$ çš„è¾“å‡ºæ˜ å°„ | æŒ‡å‘æ•°æ®æµå½¢çš„æœ€ä¼˜é‡å»ºè·¯å¾„        |\n",
    "| ä¿¡æ¯å‹ç¼©       | $\\mu_\\theta = \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\epsilon_\\theta)$ | ä¿ç•™æœ‰æ•ˆä¿¡å·ï¼Œæ»¤é™¤é«˜é¢‘å™ªå£°        |\n",
    "| åˆ†å¸ƒé”šç‚¹       | è¿‘ä¼¼çœŸå®åéªŒåˆ†å¸ƒ $q(x_{t-1}\\|x_t,x_0)$ çš„å‡å€¼ | ç¡®ä¿ç”Ÿæˆæ ·æœ¬ä½äºæ•°æ®åˆ†å¸ƒé«˜æ¦‚ç‡åŒºåŸŸ | \n",
    "\n",
    "## å››ã€é‡‡æ ·ç®—æ³•ï¼ˆç”Ÿæˆæ–°æ ·æœ¬ï¼‰\n",
    "```python\n",
    "def ddpm_sampling(model, T):\n",
    "    x_T = torch.randn_like(data)   # çº¯å™ªå£° \n",
    "    for t in range(T, 0, -1):     # ä»Tåˆ°1åå‘è¿­ä»£\n",
    "        z = torch.randn_like(x_T)  if t > 1 else 0\n",
    "        # è®¡ç®—å™ªå£°é¢„æµ‹\n",
    "        eps_theta = model(x_T, t) \n",
    "        # è®¡ç®—å‡å€¼ \n",
    "        mu_theta = (x_T - (beta_t/sqrt(1-alpha_bar_t))*eps_theta) / sqrt(alpha_t)\n",
    "        # æ›´æ–°æ ·æœ¬ \n",
    "        x_{t-1} = mu_theta + sigma_t * z\n",
    "    return x_0  # ç”Ÿæˆæ ·æœ¬ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747dd65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn  as nn \n",
    "import torch.optim  as optim\n",
    "import numpy as np \n",
    "from torch.utils.data  import DataLoader \n",
    "from torchvision import datasets, transforms \n",
    "from torchvision.utils  import save_image\n",
    "import matplotlib.pyplot  as plt\n",
    "from tqdm import tqdm\n",
    " \n",
    "# ======================\n",
    "# é…ç½®å‚æ•° \n",
    "# ======================\n",
    "device = torch.device(\"cuda\"  if torch.cuda.is_available()  else \"cpu\")\n",
    "batch_size = 64\n",
    "image_size = 32  # CIFAR-10æ ‡å‡†å°ºå¯¸\n",
    "num_epochs = 100\n",
    "T = 1000  # æ‰©æ•£æ­¥æ•°\n",
    "beta_start = 1e-4\n",
    "beta_end = 0.02\n",
    " \n",
    "# ======================\n",
    "# å™ªå£°è°ƒåº¦å™¨ \n",
    "# ======================\n",
    "class NoiseScheduler:\n",
    "    def __init__(self, T, beta_start, beta_end):\n",
    "        self.T = T \n",
    "        self.betas  = torch.linspace(beta_start,  beta_end, T).to(device)\n",
    "        self.alphas  = 1. - self.betas  \n",
    "        self.alpha_bars  = torch.cumprod(self.alphas,  dim=0)\n",
    "    \n",
    "    def add_noise(self, x_0, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_0) \n",
    "        \n",
    "        alpha_bar_t = self.alpha_bars[t].view(-1,  1, 1, 1)\n",
    "        noisy_x = torch.sqrt(alpha_bar_t)  * x_0 + torch.sqrt(1  - alpha_bar_t) * noise \n",
    "        return noisy_x, noise\n",
    " \n",
    "# ======================\n",
    "# U-Netæ¨¡å‹æ¶æ„ \n",
    "# ======================\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
    "        super().__init__()\n",
    "        self.time_mlp  = nn.Linear(time_emb_dim, out_ch)\n",
    "        if up:\n",
    "            self.conv  = nn.ConvTranspose2d(in_ch, out_ch, 3, padding=1)\n",
    "        else:\n",
    "            self.conv  = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.norm  = nn.BatchNorm2d(out_ch)\n",
    "        self.act  = nn.SiLU()\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        h = self.conv(x) \n",
    "        time_emb = self.act(self.time_mlp(t)) \n",
    "        h = h + time_emb[:, :, None, None]\n",
    "        h = self.norm(h) \n",
    "        return self.act(h) \n",
    " \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "        channels = [64, 128, 256, 512]\n",
    "        \n",
    "        # æ—¶é—´åµŒå…¥ \n",
    "        self.time_mlp  = nn.Sequential(\n",
    "            nn.Linear(1, 32),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(32, 32)\n",
    "        )\n",
    "        \n",
    "        # ä¸‹é‡‡æ ·è·¯å¾„ \n",
    "        self.down1  = Block(in_channels, channels[0], 32)\n",
    "        self.down2  = Block(channels[0], channels[1], 32)\n",
    "        self.down3  = Block(channels[1], channels[2], 32)\n",
    "        \n",
    "        # æœ€åº•å±‚\n",
    "        self.bottleneck  = Block(channels[2], channels[3], 32)\n",
    "        \n",
    "        # ä¸Šé‡‡æ ·è·¯å¾„ \n",
    "        self.up1  = Block(channels[3] + channels[2], channels[2], 32, up=True)\n",
    "        self.up2  = Block(channels[2] + channels[1], channels[1], 32, up=True)\n",
    "        self.up3  = Block(channels[1] + channels[0], channels[0], 32, up=True)\n",
    "        \n",
    "        # è¾“å‡ºå±‚ \n",
    "        self.out  = nn.Conv2d(channels[0], out_channels, 1)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # æ—¶é—´åµŒå…¥\n",
    "        t = t.unsqueeze(-1).float() \n",
    "        t_emb = self.time_mlp(t) \n",
    "        \n",
    "        # ä¸‹é‡‡æ ·\n",
    "        d1 = self.down1(x,  t_emb)\n",
    "        d2 = self.down2(d1,  t_emb)\n",
    "        d3 = self.down3(d2,  t_emb)\n",
    "        \n",
    "        # ç“¶é¢ˆå±‚ \n",
    "        bottleneck = self.bottleneck(d3,  t_emb)\n",
    "        \n",
    "        # ä¸Šé‡‡æ ·\n",
    "        u1 = self.up1(torch.cat([bottleneck,  d3], dim=1), t_emb)\n",
    "        u2 = self.up2(torch.cat([u1,  d2], dim=1), t_emb)\n",
    "        u3 = self.up3(torch.cat([u2,  d1], dim=1), t_emb)\n",
    "        \n",
    "        return self.out(u3) \n",
    " \n",
    "# ======================\n",
    "# è®­ç»ƒå‡½æ•° \n",
    "# ======================\n",
    "def train(model, dataloader, optimizer, scheduler, epochs=T):\n",
    "    model.train() \n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0 \n",
    "        for images, _ in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images = images.to(device) \n",
    "            \n",
    "            # éšæœºé‡‡æ ·æ—¶é—´æ­¥\n",
    "            t = torch.randint(0,  T, (images.shape[0],)).to(device) \n",
    "            \n",
    "            # æ·»åŠ å™ªå£° \n",
    "            noisy_images, noise = scheduler.add_noise(images,  t)\n",
    "            \n",
    "            # é¢„æµ‹å™ªå£° \n",
    "            predicted_noise = model(noisy_images, t)\n",
    "            \n",
    "            # è®¡ç®—æŸå¤± \n",
    "            loss = loss_fn(predicted_noise, noise)\n",
    "            \n",
    "            # åå‘ä¼ æ’­\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            \n",
    "            total_loss += loss.item() \n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # æ¯10ä¸ªepochä¿å­˜ä¸€æ¬¡æ¨¡å‹\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save(model.state_dict(),  f\"ddpm_epoch_{epoch+1}.pth\")\n",
    "    \n",
    "    return model\n",
    " \n",
    "# ======================\n",
    "# é‡‡æ ·ç”Ÿæˆå›¾åƒ \n",
    "# ======================\n",
    "def sample(model, scheduler, n_images=16):\n",
    "    model.eval() \n",
    "    with torch.no_grad(): \n",
    "        # ä»éšæœºå™ªå£°å¼€å§‹\n",
    "        x = torch.randn(n_images,  3, image_size, image_size).to(device)\n",
    "        \n",
    "        for t_step in tqdm(reversed(range(T)), desc=\"Generating\"):\n",
    "            t = torch.full((n_images,),  t_step, device=device, dtype=torch.long) \n",
    "            \n",
    "            # é¢„æµ‹å™ªå£°\n",
    "            pred_noise = model(x, t)\n",
    "            \n",
    "            # è®¡ç®—ç³»æ•° \n",
    "            alpha = scheduler.alphas[t][:,  None, None, None]\n",
    "            alpha_bar = scheduler.alpha_bars[t][:,  None, None, None]\n",
    "            beta = scheduler.betas[t][:,  None, None, None]\n",
    "            \n",
    "            # è®¡ç®—é‡æ–°å‚æ•°åŒ–çš„å‡å€¼\n",
    "            if t_step > 0:\n",
    "                noise = torch.randn_like(x) \n",
    "            else:\n",
    "                noise = torch.zeros_like(x) \n",
    "                \n",
    "            # DDPMé‡‡æ ·å…¬å¼\n",
    "            x = (1 / torch.sqrt(alpha))  * (\n",
    "                x - ((1 - alpha) / (torch.sqrt(1  - alpha_bar))) * pred_noise\n",
    "            ) + torch.sqrt(beta)  * noise \n",
    "            \n",
    "        # å°†å›¾åƒç¼©æ”¾åˆ°[0,1]èŒƒå›´\n",
    "        x = (x.clamp(-1,  1) + 1) / 2 \n",
    "        save_image(x, \"generated_samples.png\",  nrow=4)\n",
    "        return x\n",
    "\n",
    "class MixedPrecision():\n",
    "    def before_fit(self, learn): self.scaler = torch.cuda.amp.GradScaler('cuda')\n",
    "    def before_batch(self, learn):\n",
    "        self.autocast = torch.autocast(\"cuda\", dtype=torch.float16)\n",
    "        self.autocast.__enter__()\n",
    "    def after_loss(self, learn): self.autocast.__exit__(None, None, None)\n",
    "    def backward(self, learn): self.scaler.scale(learn.loss).backward()\n",
    "    def step(self, learn):\n",
    "        self.scaler.step(learn.opt)\n",
    "        self.scaler.update()\n",
    "\n",
    "# ======================\n",
    "# ä¸»ç¨‹åº \n",
    "# ======================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. å‡†å¤‡æ•°æ® \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    \n",
    "    # 2. åˆå§‹åŒ–ç»„ä»¶ \n",
    "    noise_scheduler = NoiseScheduler(T, beta_start, beta_end)\n",
    "    model = UNet().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(),  lr=1e-4)\n",
    "    \n",
    "    # 3. è®­ç»ƒæ¨¡å‹ \n",
    "    print(\"Starting training...\")\n",
    "    trained_model = train(model, dataloader, optimizer, noise_scheduler, num_epochs)\n",
    "    \n",
    "    # 4. ä¿å­˜æœ€ç»ˆæ¨¡å‹\n",
    "    torch.save(trained_model.state_dict(),  \"ddpm_final.pth\") \n",
    "    print(\"Training completed. Model saved.\")\n",
    "    \n",
    "    # 5. ç”Ÿæˆæ ·æœ¬ \n",
    "    print(\"Generating samples...\")\n",
    "    generated_images = sample(trained_model, noise_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4903d17",
   "metadata": {},
   "source": [
    "# Denoising Diffusion Implicit Models - DDIM\n",
    "\n",
    "# DDIMï¼ˆDenoising Diffusion Implicit Modelsï¼‰æ ¸å¿ƒåŸç†ä¸ç®—æ³• \n",
    " \n",
    "## 1. æ ¸å¿ƒæ€æƒ³ \n",
    "DDIM æ˜¯æ‰©æ•£æ¨¡å‹çš„æ”¹è¿›å½¢å¼ï¼Œé€šè¿‡**éé©¬å°”å¯å¤«é“¾çš„ç¡®å®šæ€§è¿‡ç¨‹**å®ç°é«˜è´¨é‡ç”Ÿæˆï¼ŒåŒæ—¶æ”¯æŒ**å¤§å¹…å‡å°‘é‡‡æ ·æ­¥éª¤**ï¼ˆå¦‚10-50æ­¥ï¼‰ã€‚å…¶å…³é”®çªç ´åœ¨äºï¼š\n",
    "- å°†æ‰©æ•£è¿‡ç¨‹é‡æ–°å‚æ•°åŒ–ä¸ºå¯é€†çš„éé©¬å°”å¯å¤«é“¾ \n",
    "- é€šè¿‡éšå¼æ¦‚ç‡æ¨¡å‹å®ç°ç¡®å®šæ€§é‡‡æ · \n",
    "- ä¿æŒä¸DDPMç›¸åŒçš„è®­ç»ƒç›®æ ‡ï¼ˆå¯å¤ç”¨å·²æœ‰æ¨¡å‹ï¼‰\n",
    " \n",
    "## 2. æ ¸å¿ƒç®—æ³•æ­¥éª¤ \n",
    " \n",
    "### 2.1 å‰å‘è¿‡ç¨‹ï¼ˆéé©¬å°”å¯å¤«ï¼‰\n",
    "å®šä¹‰ä»»æ„æ—¶é—´åºåˆ—å­é›† $\\{Ï„_1,Ï„_2,...,Ï„_T\\}$ï¼Œå‰å‘è¿‡ç¨‹ä¸ºï¼š\n",
    "$$\n",
    "q_Ïƒ(x_{1:T}|x_0) = q_Ïƒ(x_T|x_0)\\prod_{t=2}^T q_Ïƒ(x_{Ï„_{t-1}}|x_{Ï„_t},x_0)\n",
    "$$\n",
    "å…¶ä¸­ $Ïƒ$ æ§åˆ¶éšæœºæ€§ï¼ˆå½“ $Ïƒ=0$ æ—¶ä¸ºç¡®å®šæ€§è¿‡ç¨‹ï¼‰\n",
    " \n",
    "### 2.2 åå‘è¿‡ç¨‹ï¼ˆå…³é”®å…¬å¼ï¼‰\n",
    "é‡‡æ ·å…¬å¼ï¼š\n",
    "$$\n",
    "x_{t-1} = \\sqrt{\\barÎ±_{t-1}} \\left( \\frac{x_t - \\sqrt{1-\\barÎ±_t}Îµ_Î¸(x_t,t)}{\\sqrt{\\barÎ±_t}} \\right) + \\sqrt{1-\\barÎ±_{t-1}-Ïƒ_t^2}Â·Îµ_Î¸(x_t,t) + Ïƒ_tÎµ \n",
    "$$\n",
    "å…¶ä¸­ï¼š\n",
    "- $Îµ_Î¸(x_t,t)$ï¼šè®­ç»ƒå¥½çš„å™ªå£°é¢„æµ‹ç½‘ç»œ \n",
    "- $\\barÎ±_t$ï¼šç´¯ç§¯å™ªå£°è°ƒåº¦å‚æ•° \n",
    "- $Ïƒ_t$ï¼šæ§åˆ¶éšæœºæ€§çš„è¶…å‚æ•° \n",
    " \n",
    "## 3. å…³é”®æ•°å­¦æ¨å¯¼ \n",
    "### 3.1 å˜åˆ†ä¸‹ç•Œé‡æ„ \n",
    "ä¿æŒä¸DDPMç›¸åŒçš„è®­ç»ƒç›®æ ‡ï¼š\n",
    "$$\n",
    "L_{Î¸} = \\mathbb{E}_{t,x_0,Îµ}[||Îµ - Îµ_Î¸(x_t,t)||^2]\n",
    "$$\n",
    " \n",
    "### 3.2 ç¡®å®šæ€§é‡‡æ ·ï¼ˆÏƒ=0ï¼‰\n",
    "å½“ $Ïƒ_t=0$ æ—¶ï¼Œé‡‡æ ·è¿‡ç¨‹å˜ä¸ºï¼š\n",
    "$$\n",
    "x_{t-1} = \\sqrt{\\barÎ±_{t-1}}f_Î¸(x_t,t) + \\sqrt{1-\\barÎ±_{t-1}}Îµ_Î¸(x_t,t)\n",
    "$$\n",
    "å…¶ä¸­ $f_Î¸(x_t,t) = (x_t - \\sqrt{1-\\barÎ±_t}Îµ_Î¸(x_t,t))/\\sqrt{\\barÎ±_t}$\n",
    "\n",
    "### DDIM æ—¶é—´å­åºåˆ—é‡å‚æ•°åŒ–\n",
    "DDIM é€šè¿‡é‡æ„åŸå§‹æ‰©æ•£è¿‡ç¨‹çš„æ—¶é—´æ­¥åºåˆ— $\\{1,2,...,T\\}$ ä¸ºä»»æ„å­åºåˆ— $\\{\\tau_1,\\tau_2,...,\\tau_S\\}$ï¼ˆæ»¡è¶³ $S \\ll T$ï¼‰ï¼Œå®ç°è·¨æ­¥è®¡ç®—ã€‚æ ¸å¿ƒå…¬å¼å¦‚ä¸‹ï¼š\n",
    " \n",
    "####  ğŸ§® è·¨æ­¥è®¡ç®—å…¬å¼ \n",
    "$$x_{\\tau_{i-1}} = \\sqrt{\\bar{\\alpha}_{\\tau_{i-1}}} \\left( \\frac{x_{\\tau_i} - \\sqrt{1-\\bar{\\alpha}_{\\tau_i}} \\epsilon_\\theta (x_{\\tau_i}, \\tau_i)} {\\sqrt{\\bar{\\alpha}_{\\tau_i}}} \\right) + \\sqrt{1-\\bar{\\alpha}_{\\tau_{i-1}}} \\epsilon_\\theta (x_{\\tau_i}, \\tau_i)$$\n",
    " \n",
    "####  ç´¯ç§¯å™ªå£°è°ƒåº¦\n",
    "$$\\bar{\\alpha}_{\\tau_{i-1}} = \\prod_{s=1}^{\\tau_{i-1}} (1-\\beta_s) \\quad \\text{(ç›´æ¥è·³è·ƒåˆ°ç›®æ ‡æ—¶é—´æ­¥)}$$\n",
    " \n",
    "---\n",
    " \n",
    "###  å…³é”®çªç ´ç‚¹\n",
    "1. **æ—¶é—´æ­¥è§£è€¦**  \n",
    "   - å­åºåˆ—æ­¥ $\\tau_i$ ä¸å‰ä¸€æ­¥ $\\tau_{i-1}$ çš„å…³ç³»**ä¸ä¾èµ–ä¸­é—´çŠ¶æ€**  \n",
    "   - ä»…é€šè¿‡ $\\bar{\\alpha}$ å‚æ•°å…³è”ï¼Œå®ç°è®¡ç®—è·¯å¾„çš„æ‹“æ‰‘è§£è€¦\n",
    " \n",
    "2. **ç´¯ç§¯å™ªå£°è°ƒåº¦**  \n",
    "   - $\\bar{\\alpha}$ çš„**æŒ‡æ•°è¡°å‡æ€§è´¨**æ˜¯è·¨æ­¥è®¡ç®—çš„æ ¸å¿ƒ  \n",
    "   - é€šè¿‡ä¹˜ç§¯å½¢å¼ $\\prod_{s=1}^{\\tau_{i-1}} (1-\\beta_s)$ ç›´æ¥å»ºæ¨¡ç´¯è®¡å™ªå£°å½±å“  \n",
    "   - å…è®¸åœ¨ä»»æ„å­åºåˆ—æ­¥é•¿é—´è¿›è¡Œç¡®å®šæ€§è·³è·ƒ\n",
    "\n",
    "## 4. ä¸DDPMçš„å…³é”®åŒºåˆ« \n",
    "| ç‰¹æ€§        | DDPM           | DDIM          |\n",
    "|-------------|----------------|---------------|\n",
    "| è¿‡ç¨‹ç±»å‹    | é©¬å°”å¯å¤«é“¾     | éé©¬å°”å¯å¤«é“¾  |\n",
    "| é‡‡æ ·æ–¹å¼    | éšæœºè¿‡ç¨‹       | ç¡®å®šæ€§è¿‡ç¨‹    |\n",
    "| é‡‡æ ·æ­¥æ•°    | é€šå¸¸éœ€è¦1000+  | å¯ä½è‡³10-50æ­¥ |\n",
    "| ç”Ÿæˆè½¨è¿¹    | å”¯ä¸€ç¡®å®š       | å¤šè·¯å¾„å¯èƒ½    |\n",
    "| è®­ç»ƒå…¼å®¹æ€§  | åŸç”Ÿæ¨¡å‹       | å®Œå…¨å…¼å®¹      |\n",
    " \n",
    "## 5. ç®—æ³•ä¼˜åŠ¿ \n",
    "1. **åŠ é€Ÿé‡‡æ ·**ï¼šç›¸æ¯”DDPMæé€Ÿ20-100å€ \n",
    "2. **è´¨é‡ä¿æŒ**ï¼šåœ¨10æ­¥é‡‡æ ·æ—¶ä»å¯ä¿æŒç”Ÿæˆè´¨é‡ \n",
    "3. **åºåˆ—æ’å€¼**ï¼šæ”¯æŒæ½œåœ¨ç©ºé—´æ’å€¼æ“ä½œ \n",
    "4. **å…¼å®¹å¤ç”¨**ï¼šå¯ç›´æ¥ä½¿ç”¨é¢„è®­ç»ƒDDPMæ¨¡å‹ \n",
    "5. **å¯æ§éšæœºæ€§**ï¼šé€šè¿‡Ïƒå‚æ•°è°ƒèŠ‚ç”Ÿæˆå¤šæ ·æ€§ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c64ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from math import sqrt \n",
    " \n",
    "class DDIMSampler(nn.Module):\n",
    "    def __init__(self, model, timesteps=1000, ddim_steps=50, eta=0.0):\n",
    "        self.model  = model  # é¢„è®­ç»ƒå¥½çš„UNetæ¨¡å‹ \n",
    "        self.timesteps  = timesteps \n",
    "        self.ddim_steps  = ddim_steps  # å­åºåˆ—æ­¥æ•°(S)\n",
    "        self.eta  = eta  # éšæœºå› å­(Î·=0æ—¶ç¡®å®šæ€§ç”Ÿæˆ)\n",
    "        \n",
    "        # ç”Ÿæˆæ—¶é—´å­åºåˆ—(Ï„_1,Ï„_2,...,Ï„_S)\n",
    "        self.time_seq  = self._generate_time_sequence()\n",
    "        # é¢„è®¡ç®—ç´¯ç§¯å™ªå£°å‚æ•°Î±_bar\n",
    "        self.alphas_cumprod = model.alphas_cumprod\n",
    " \n",
    "    def _generate_time_sequence(self):\n",
    "        \"\"\"ç”Ÿæˆæ—¶é—´æ­¥å­åºåˆ—(ç­‰å·®æ•°åˆ—é‡‡æ ·)\"\"\"\n",
    "        step_ratio = self.timesteps  // self.ddim_steps  \n",
    "        return list(range(0, self.timesteps,  step_ratio))[::-1]\n",
    " \n",
    "    def sample_step(self, x, t, t_prev):\n",
    "        \"\"\"å•æ­¥å»å™ªè¿‡ç¨‹ [12]()\"\"\"\n",
    "        # è·å–å™ªå£°é¢„æµ‹æ¨¡å‹è¾“å‡º \n",
    "        eps_theta = self.model(x,  t)\n",
    "        \n",
    "        # æå–Î±_barå‚æ•° \n",
    "        alpha_bar = self.alphas_cumprod[t] \n",
    "        alpha_bar_prev = self.alphas_cumprod[t_prev] \n",
    "        \n",
    "        # è®¡ç®—é¢„æµ‹çš„x0 (å¼(12) [12]())\n",
    "        pred_x0 = (x - sqrt(1 - alpha_bar) * eps_theta) / sqrt(alpha_bar)\n",
    "        \n",
    "        # è®¡ç®—æ–¹å·®é¡¹ \n",
    "        sigma = self.eta  * sqrt( (1 - alpha_bar_prev)/(1 - alpha_bar) * (1 - alpha_bar/alpha_bar_prev) )\n",
    "        \n",
    "        # è®¡ç®—å‡å€¼é¡¹ \n",
    "        mean = sqrt(alpha_bar_prev) * pred_x0 + sqrt(1 - alpha_bar_prev - sigma**2) * eps_theta \n",
    "        \n",
    "        # ç”Ÿæˆå‰ä¸€æ­¥æ ·æœ¬ \n",
    "        if self.eta  == 0:\n",
    "            return mean \n",
    "        else:\n",
    "            return mean + sigma * torch.randn_like(x) \n",
    " \n",
    "    def ddim_sample(self, shape=(1,3,64,64)):\n",
    "        \"\"\"å®Œæ•´é‡‡æ ·æµç¨‹\"\"\"\n",
    "        x = torch.randn(shape).to(device) \n",
    "        \n",
    "        for i in range(len(self.time_seq)-1): \n",
    "            t = self.time_seq[i] \n",
    "            t_prev = self.time_seq[i+1] \n",
    "            x = self.sample_step(x,  t, t_prev)\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b8a14c",
   "metadata": {},
   "source": [
    "# ç‰›é¡¿-èˆ’å°”èŒ¨è¿­ä»£æ³•ï¼ˆNewton-Schulz Iterationï¼‰è¯¦è§£ \n",
    " \n",
    "## 1. åŸºæœ¬åŸç† \n",
    "ç‰›é¡¿-èˆ’å°”èŒ¨è¿­ä»£æ³•æ˜¯ç»å…¸ç‰›é¡¿è¿­ä»£æ³•åœ¨çŸ©é˜µè¿ç®—ä¸­çš„æ‰©å±•ï¼Œç”¨äºæ±‚è§£çŸ©é˜µå¹³æ–¹æ ¹é—®é¢˜ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡ä¸åŠ¨ç‚¹è¿­ä»£é€¼è¿‘çŸ©é˜µå¹³æ–¹æ ¹ï¼Œé¿å…äº†æ˜¾å¼çš„çŸ©é˜µåˆ†è§£å’Œæ±‚é€†æ“ä½œ\n",
    " \n",
    "### æ•°å­¦è¡¨è¾¾å¼ \n",
    "ç»™å®šéå¥‡å¼‚çŸ©é˜µ$A \\in \\mathbb{R}^{n \\times n}$ï¼Œå¯»æ‰¾çŸ©é˜µ$X$ä½¿å¾—ï¼š\n",
    "$$ X^2 = A $$\n",
    "ç‰›é¡¿-èˆ’å°”èŒ¨è¿­ä»£å…¬å¼ä¸ºï¼š\n",
    "$$ X_{k+1} = \\frac{1}{2} X_k (3I - X_k^2 A) $$\n",
    "å…¶ä¸­$X_0$ä¸ºåˆå§‹çŒœæµ‹çŸ©é˜µï¼Œé€šå¸¸å–$X_0 = A$æˆ–$X_0 = \\frac{A}{\\|A\\|_2}$ã€‚\n",
    "\n",
    "# ç”Ÿæˆæ¨¡å‹è¯„ä¼°æŒ‡æ ‡è¯¦è§£ï¼šFIDã€MMDä¸KID \n",
    "## 1. FIDï¼ˆFrÃ©chet Inception Distanceï¼‰\n",
    "### åŸç† \n",
    "- **æ•°å­¦åŸºç¡€**ï¼šè®¡ç®—ä¸¤ä¸ªå¤šå…ƒé«˜æ–¯åˆ†å¸ƒä¹‹é—´çš„FrÃ©chetè·ç¦»ï¼š\n",
    "  $$ \\text{FID} = \\|\\mu_1 - \\mu_2\\|^2 + \\text{Tr}(\\Sigma_1 + \\Sigma_2 - 2(\\Sigma_1 \\Sigma_2)^{1/2}) $$\n",
    "  å…¶ä¸­ $\\mu$ ä¸ºå‡å€¼å‘é‡ï¼Œ$\\Sigma$ ä¸ºåæ–¹å·®çŸ©é˜µ[1]()ã€‚\n",
    "- **ç‰¹å¾æå–**ï¼šä½¿ç”¨Inception-v3æ¨¡å‹ï¼ˆç§»é™¤åˆ†ç±»å±‚ï¼‰æå–2048ç»´å›¾åƒç‰¹å¾å‘é‡ã€‚\n",
    "- **æ ¸å¿ƒæ€æƒ³**ï¼šé€šè¿‡ç‰¹å¾ç©ºé—´çš„ç»Ÿè®¡é‡ï¼ˆå‡å€¼ã€åæ–¹å·®ï¼‰é‡åŒ–åˆ†å¸ƒå·®å¼‚ï¼Œå€¼è¶Šå°è¡¨ç¤ºç”Ÿæˆå›¾åƒä¸çœŸå®å›¾åƒè¶Šç›¸ä¼¼[2]()ã€‚\n",
    "### è®¡ç®—æ­¥éª¤ \n",
    "1. **ç‰¹å¾ç»Ÿè®¡**ï¼šè®¡ç®—çœŸå®å›¾åƒå’Œç”Ÿæˆå›¾åƒç‰¹å¾çš„å‡å€¼å‘é‡ä¸åæ–¹å·®çŸ©é˜µã€‚\n",
    "2. **çŸ©é˜µè¿ç®—**ï¼š\n",
    "   - è®¡ç®—åæ–¹å·®çŸ©é˜µä¹˜ç§¯çš„å¹³æ–¹æ ¹ï¼ˆ`linalg.sqrtm` ï¼‰\n",
    "   - ç»„åˆå‡å€¼å·®å¹³æ–¹ã€åæ–¹å·®è¿¹å’Œå¹³æ–¹æ ¹è¿¹ \n",
    "3. **è¾“å‡º**ï¼šæ ‡é‡å€¼ï¼ˆ`.item()`æå–ï¼‰ï¼Œå€¼è¶Šä½è¡¨ç¤ºç”Ÿæˆè´¨é‡è¶Šå¥½ã€‚\n",
    "### ç‰¹ç‚¹ä¸åº”ç”¨ \n",
    "- **ä¼˜åŠ¿**ï¼šä¸äººç±»è§†è§‰æ„ŸçŸ¥é«˜åº¦ä¸€è‡´ï¼ŒGANè¯„ä¼°çš„é»„é‡‘æ ‡å‡†[[1][2]()ã€‚\n",
    "- **å±€é™**ï¼šå‡è®¾ç‰¹å¾æœä»é«˜æ–¯åˆ†å¸ƒï¼Œå¯¹éé«˜æ–¯åˆ†å¸ƒå¯èƒ½é«˜ä¼°å·®å¼‚ã€‚\n",
    "- **å…¸å‹åœºæ™¯**ï¼šStyleGANã€ProGANç­‰ç”Ÿæˆæ¨¡å‹çš„å…¨å±€åˆ†å¸ƒè¯„ä¼°ã€‚\n",
    "---\n",
    "## 2. MMDï¼ˆMaximum Mean Discrepancyï¼‰\n",
    "### åŸç† \n",
    "- **æ•°å­¦åŸºç¡€**ï¼šåŸºäºå†ç”Ÿæ ¸å¸Œå°”ä¼¯ç‰¹ç©ºé—´ï¼ˆRKHSï¼‰çš„å‡å€¼å·®å¼‚ï¼š\n",
    "  $$ \\text{MMD}^2 = \\mathbb{E}[k(x,x')] + \\mathbb{E}[k(y,y')] - 2\\mathbb{E}[k(x,y)] $$\n",
    "- **æ ¸å‡½æ•°**ï¼šä»£ç é‡‡ç”¨ä¸‰æ¬¡å¤šé¡¹å¼æ ¸ $k(a,b) = (a \\cdot b^T / d + 1)^3$ï¼Œå…¶ä¸­ $d$ ä¸ºç‰¹å¾ç»´åº¦[7]()ã€‚\n",
    "- **æ— åä¼°è®¡**ï¼šå‰”é™¤æ ¸çŸ©é˜µå¯¹è§’çº¿å…ƒç´ ï¼ˆ`kxx_sum = kxx.sum()  - kxx.diagonal().sum()` ï¼‰ï¼Œé¿å…æ ·æœ¬è‡ªç›¸ä¼¼å¹²æ‰°ã€‚\n",
    "### è®¡ç®—æ­¥éª¤ \n",
    "1. **æ ¸çŸ©é˜µè®¡ç®—**ï¼šåŒç±»æ ·æœ¬æ ¸ï¼ˆ`kxx, kyy`ï¼‰ä¸è·¨ç±»æ ¸ï¼ˆ`kxy`ï¼‰ã€‚\n",
    "2. **ç»Ÿè®¡é‡ç»„åˆ**ï¼š\n",
    "   - $kxx$ å’Œ $kyy$ çš„å‰”é™¤å¯¹è§’çº¿å’Œ \n",
    "   - $kxy$ çš„å®Œæ•´å’Œ \n",
    "3. **æ ‡å‡†åŒ–è¾“å‡º**ï¼šæŒ‰æ ·æœ¬é‡åŠ æƒç»„åˆç»“æœã€‚\n",
    "### ç‰¹ç‚¹ä¸åº”ç”¨ \n",
    "- **ä¼˜åŠ¿**ï¼šéå‚æ•°æ–¹æ³•ï¼Œä¸ä¾èµ–æ•°æ®åˆ†å¸ƒå‡è®¾[7]()ã€‚\n",
    "- **çµæ´»æ€§**ï¼šå¯é€šè¿‡æ›´æ¢æ ¸å‡½æ•°ï¼ˆå¦‚é«˜æ–¯æ ¸ï¼‰é€‚åº”ä¸åŒä»»åŠ¡ã€‚\n",
    "- **å…¸å‹åœºæ™¯**ï¼šè¿ç§»å­¦ä¹ çš„åŸŸé€‚åº”ã€åŒæ ·æœ¬å‡è®¾æ£€éªŒã€‚\n",
    "---\n",
    "## 3. KIDï¼ˆKernel Inception Distanceï¼‰\n",
    "### åŸç† \n",
    "- **æ”¹è¿›MMD**ï¼šé€šè¿‡åˆ†å—è®¡ç®—MMDçš„å‡å€¼ï¼Œè§£å†³å¤§æ ·æœ¬è®¡ç®—ç“¶é¢ˆï¼š\n",
    "  $$ \\text{KID} = \\frac{1}{n}\\sum_{i=1}^n \\text{MMD}^2(S_{x,i}, S_{y,i}) $$\n",
    "- **åˆ†å—ç­–ç•¥**ï¼šé»˜è®¤å—å¤§å°â‰¤50ï¼Œæœ€å°åˆ†å—æ•°â‰¥4ï¼ˆ`n = max(ceil(min(xs/maxs, ys/maxs)), 4)`ï¼‰[6]()ã€‚\n",
    "- **æ— åæ€§**ï¼šä¸‰æ¬¡æ ¸çš„æ— åä¼°è®¡æ›´ç¬¦åˆäººç±»æ„ŸçŸ¥[[3][7]()ã€‚\n",
    "### è®¡ç®—æ­¥éª¤ \n",
    "1. **åŠ¨æ€åˆ†å—**ï¼šæ ¹æ®æ ·æœ¬é‡è®¡ç®—å­é›†æ•°é‡ $n$ã€‚\n",
    "2. **å­é›†MMDè®¡ç®—**ï¼šå¾ªç¯è®¡ç®—æ¯ä¸ªå­é›†çš„ `_squared_mmd`ã€‚\n",
    "3. **ç»“æœå¹³å‡**ï¼šè¾“å‡ºåˆ†å—MMDçš„å‡å€¼ï¼ˆ`mmd/n`ï¼‰ã€‚\n",
    "### ç‰¹ç‚¹ä¸åº”ç”¨ \n",
    "- **ä¼˜åŠ¿**ï¼šå¯¹å°æ ·æœ¬æ›´é²æ£’ï¼Œè®¡ç®—æ•ˆç‡é«˜äºFID[6]()ã€‚\n",
    "- **å…¸å‹åœºæ™¯**ï¼šè¯„ä¼°ç”Ÿæˆå›¾åƒçš„å±€éƒ¨ç‰¹å¾ä¸€è‡´æ€§ï¼ˆå¦‚StyleGANç»†èŠ‚çº¹ç†ï¼‰ã€‚\n",
    "---\n",
    "## æŒ‡æ ‡å¯¹æ¯”æ€»ç»“ \n",
    "| **æŒ‡æ ‡** | **ç†è®ºåŸºç¡€**       | **è®¡ç®—å¤æ‚åº¦** | **æ•°æ®å‡è®¾** | **æ ¸å¿ƒä¼˜åŠ¿**               |\n",
    "|----------|---------------------|----------------|--------------|----------------------------|\n",
    "| FID      | FrÃ©chetè·ç¦»         | é«˜ï¼ˆçŸ©é˜µåˆ†è§£ï¼‰ | é«˜æ–¯åˆ†å¸ƒ     | å…¨å±€åˆ†å¸ƒè¯„ä¼°               |\n",
    "| MMD      | æ ¸ç©ºé—´å‡å€¼å·®å¼‚      | ä¸­             | æ—            | éå‚æ•°ã€çµæ´»æ ¸å‡½æ•°         |\n",
    "| KID      | MMDåˆ†å—å¹³å‡         | ä½             | æ—            | å±€éƒ¨ç‰¹å¾ä¸€è‡´æ€§ã€å°æ ·æœ¬é²æ£’ |\n",
    "> **åº”ç”¨å»ºè®®**ï¼š  \n",
    "> - éœ€å¿«é€Ÿè¯„ä¼°å…¨å±€è´¨é‡ â†’ **FID**  \n",
    "> - å…³æ³¨å±€éƒ¨ç»†èŠ‚æˆ–æ— åˆ†å¸ƒå‡è®¾ â†’ **KID**  \n",
    "> - éå›¾åƒæ•°æ®æˆ–è¿ç§»å­¦ä¹  â†’ **MMD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sqrtm_newton_schulz(mat, num_iters=100):\n",
    "    mat_nrm = mat.norm()\n",
    "    mat = mat.double()\n",
    "    Y = mat/mat_nrm\n",
    "    n = len(mat)\n",
    "    I = torch.eye(n, n).to(mat)\n",
    "    Z = torch.eye(n, n).to(mat)\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        T = (3*I - Z@Y)/2\n",
    "        Y,Z = Y@T,T@Z\n",
    "        res = Y*mat_nrm.sqrt()\n",
    "        if ((mat-(res@res)).norm()/mat_nrm).abs()<=1e-6: break\n",
    "    return res\n",
    "\n",
    "def _calc_stats(feats):\n",
    "    feats = feats.squeeze()\n",
    "    return feats.mean(0),feats.T.cov()\n",
    "\n",
    "def _calc_fid(m1,c1,m2,c2):\n",
    "#     csr = _sqrtm_newton_schulz(c1@c2)\n",
    "    csr = tensor(linalg.sqrtm(c1@c2, 256).real)\n",
    "    return (((m1-m2)**2).sum() + c1.trace() + c2.trace() - 2*csr.trace()).item()\n",
    "\n",
    "def _squared_mmd(x, y):\n",
    "    def k(a,b): return (a@b.transpose(-2,-1)/a.shape[-1]+1)**3\n",
    "    m,n = x.shape[-2],y.shape[-2]\n",
    "    kxx,kyy,kxy = k(x,x), k(y,y), k(x,y)\n",
    "    kxx_sum = kxx.sum([-1,-2])-kxx.diagonal(0,-1,-2).sum(-1)\n",
    "    kyy_sum = kyy.sum([-1,-2])-kyy.diagonal(0,-1,-2).sum(-1)\n",
    "    kxy_sum = kxy.sum([-1,-2])\n",
    "    return kxx_sum/m/(m-1) + kyy_sum/n/(n-1) - kxy_sum*2/m/n\n",
    "\n",
    "def _calc_kid(x, y, maxs=50):\n",
    "    xs,ys = x.shape[0],y.shape[0]\n",
    "    n = max(math.ceil(min(xs/maxs, ys/maxs)), 4)\n",
    "    mmd = 0.\n",
    "    for i in range(n):\n",
    "        cur_x = x[round(i*xs/n) : round((i+1)*xs/n)]\n",
    "        cur_y = y[round(i*ys/n) : round((i+1)*ys/n)]\n",
    "        mmd += _squared_mmd(cur_x, cur_y)\n",
    "    return (mmd/n).item()\n",
    "\n",
    "class ImageEval:\n",
    "    def __init__(self, model, dls, cbs=None):\n",
    "        self.learn = TrainLearner(model, dls, loss_func=fc.noop, cbs=cbs, opt_func=None)\n",
    "        self.feats = self.learn.capture_preds()[0].float().cpu().squeeze()\n",
    "        self.stats = _calc_stats(self.feats)\n",
    "\n",
    "    def get_feats(self, samp):\n",
    "        self.learn.dls = DataLoaders([],[(samp, tensor([0]))])\n",
    "        return self.learn.capture_preds()[0].float().cpu().squeeze()\n",
    "\n",
    "    def fid(self, samp): return _calc_fid(*self.stats, *_calc_stats(self.get_feats(samp)))\n",
    "    def kid(self, samp): return _calc_kid(self.feats, self.get_feats(samp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688709c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
